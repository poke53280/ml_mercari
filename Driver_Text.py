
#
# Hub for
#
# Text processing and pipeline into models.
# Non text problems using text problem pipelines
#
#
# Describe and show code for:
#
# word and char n-grams.
# nn
# embeddings
# general sequences of states
#
#
# char gram => nn
# wordbatch
#
# antti talking => text example
#
# Organize existing code.
#
# Take in code from Kaggle text competitions and CTF predictions.
#
# text_processor.py: Sequences, keras, nn attempts. Embeddings on general event/interval sequences.
#
#
#


# Areas:


# Actual text:
# Spell check. HTML and other cleanings.
#
#
#
# (Language specific) dictionaries
# Word2Vec et.c.
#
# stemmer. tokenize.
#
# parts of speech tagging. Named Entity Recognition.
#


#
# Sequences. General embeddings. Non-language knowledge dependent comprehension. (char level ngram)
#

# => Model X/ feature vectors

#
# From Toxic: 
# Pseudo labling (PL). 
# Pretrained embeddings. FastText. Glove.
# Translations as train/test-time augmentation (TTA) Pavel Ostyakov
#
#






